# -*- coding: utf-8 -*-
"""ULTIMATE999.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ab_bde9u_FRb54DylbRYLraOwhleolB
"""

# Commented out IPython magic to ensure Python compatibility.
# %%local
# %matplotlib inline

from pyspark.sql import SparkSession
from pyspark.sql.functions import length
from pyspark.sql.functions import col, count, when
spark = SparkSession.builder.appName("MyApp").getOrCreate()

# Replace 'path/to/your/csvfile.csv' with the path to your CSV file
csv_file_path = 's3://msba2024-emr-integration1/cleaned_Books_rating.csv'
# Read the CSV file into a DataFrame
df_rating = spark.read.csv(csv_file_path, header=True, inferSchema=True)
# Show the DataFrame
df_rating.show()

# Create a "output" folder in S3 before running the code below
df_rating.write.option("path", "s3://msba2024-emr-integration1/rating")\
    .mode("overwrite")\
    .saveAsTable("rating")

spark.sql("SELECT * FROM rating").show()

# Assuming you have a SparkSession instance named 'spark'
# Query to select rows from the year 2000
query = """
SELECT *
FROM rating
WHERE YEAR(Time) = 2000
"""

# Executing the query
df_2000 = spark.sql(query)

# Show the results
df_2000.show()

df_rating.printSchema()

# Replace 'path/to/your/csvfile.csv' with the path to your CSV file
csv_file_path2 = 's3://msba2024-emr-integration1/cleaned_Books_data (1).csv'
# Read the CSV file into a DataFrame
df_data = spark.read.csv(csv_file_path2, header=True, inferSchema=True)
# Show the DataFrame
df_data.show()

df_rating.write.option("path", "s3://msba2024-emr-integration1/data")\
    .mode("overwrite")\
    .saveAsTable("data")

spark.sql("SELECT * FROM data").show()

spark.sql("DESCRIBE data").show()

from pyspark.sql.functions import monotonically_increasing_id

# Select distinct authors and add a unique ID
authors_df = df_data.select("authors").withColumn("AuthorID", monotonically_increasing_id())

# Save to S3
authors_df.write.mode("overwrite").option("path", "s3://msba2024-emr-integration1/Authors").saveAsTable("Authors")

from pyspark.sql.functions import monotonically_increasing_id

# Select distinct publishers and add a unique ID
publishers_df = df_data.select("publisher").withColumn("PublisherID", monotonically_increasing_id())

# Save to S3
publishers_df.write.mode("overwrite").option("path", "s3://msba2024-emr-integration1/Publishers").saveAsTable("Publishers")

from pyspark.sql.functions import monotonically_increasing_id

# Select distinct categories and add a unique ID
categories_df = df_data.select("categories").withColumn("CategoriesID", monotonically_increasing_id())

# Save to S3
categories_df.write.mode("overwrite").option("path", "s3://msba2024-emr-integration1/Categories").saveAsTable("Categories")

# Assuming 'df_data' is your DataFrame
books_df = df_data.selectExpr("Title",
                              "authors",
                              "publisher",
                              "categories",
                              "description AS Description",
                              "image AS Image",
                              "previewLink AS PreviewLink",
                              "publishedDate AS PublishedDate",
                              "infoLink AS InfoLink",
                              "cast(ratingsCount as int) AS RatingsCount")

# Assuming you have the logic to add AuthorID, PublisherID, and CategoriesID
# For example, this could be a join operation with the respective tables
# books_df = books_df.join(authors_df, ...)
# books_df = books_df.join(publishers_df, ...)
# books_df = books_df.join(categories_df, ...)
books_df.write.mode("overwrite").option("path", "s3://msba2024-emr-integration1/Books").saveAsTable("Books")

from pyspark.sql.functions import monotonically_increasing_id

# Assuming 'persistent_table' is your DataFrame
# Adding a 'ReviewID' column to mimic an auto-incrementing primary key
reviews_ratings_df = df_rating.withColumn("ReviewID", monotonically_increasing_id()) \
                                     .selectExpr("ReviewID",
                                                 "Title",
                                                 "User_id as UserID",
                                                 "Score",
                                                 "Time",
                                                 "review_Title as ReviewTitle",
                                                 "review_Text as ReviewText",
                                                 "n_helpful_review as NHelpfulReview",
                                                 "n_views as NViews")
reviews_ratings_df.write.mode("overwrite").option("path", "s3://msba2024-emr-integration1/reviews_rating").saveAsTable("reviews_rating")

spark.sql("SELECT * FROM Authors").show()

spark.sql("SELECT * FROM Publishers").show()

spark.sql("SELECT * FROM Categories").show()

spark.sql("SELECT * FROM Books").show()

spark.sql("SELECT * FROM reviews_rating").show()

# Business insights and queries

# 1
# Books with Most Helpful Reviews
# Find books with the highest number of helpful reviews.

spark.sql("""
    SELECT B.Title, SUM(RR.NHelpfulReview) as TotalHelpfulReviews
    FROM Books B JOIN reviews_rating RR ON B.Title = RR.Title
    GROUP BY B.Title
    ORDER BY TotalHelpfulReviews DESC
    LIMIT 10
""").show()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# Assuming 'df_books_reviews' is the Spark DataFrame containing the result of your SQL query
df_books_reviews = spark.sql("""
SELECT B.Title, SUM(RR.NHelpfulReview) as TotalHelpfulReviews
FROM Books B JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Title
ORDER BY TotalHelpfulReviews DESC
LIMIT 10
""")

# Convert the DataFrame to Pandas for visualization
pandas_books_reviews = df_books_reviews.toPandas()

# Sorting the DataFrame by 'TotalHelpfulReviews' for better visualization
pandas_books_reviews.sort_values('TotalHelpfulReviews', inplace=True, ascending=True)

# Plotting
plt.figure(figsize=(12, 8))

# Create a horizontal bar chart
plt.barh(pandas_books_reviews['Title'], pandas_books_reviews['TotalHelpfulReviews'], color='green')

# Add labels and title
plt.xlabel('Total Helpful Reviews')
plt.ylabel('Book Title')
plt.title('Top 10 Books by Most Helpful Reviews')

# Display the values on the bars for clarity
for index, value in enumerate(pandas_books_reviews['TotalHelpfulReviews']):
    plt.text(value, index, str(value))

# Show the plot
plt.show()

# %matplot plt

# 2
# User Engagement Analysis
# Analyze how user engagement (views and helpful reviews) changes over time.

spark.sql("""
    SELECT YEAR(RR.Time) as Year, SUM(RR.NViews) as TotalViews, SUM(RR.NHelpfulReview) as TotalHelpfulReviews
    FROM reviews_rating RR
    GROUP BY Year
    ORDER BY Year;
""").show()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# Run SQL query to aggregate data by year
agg_query = """
SELECT YEAR(Time) as Year, SUM(NViews) as TotalViews, SUM(NHelpfulReview) as TotalHelpfulReviews
FROM reviews_rating
GROUP BY YEAR(Time)
ORDER BY YEAR(Time)
"""
df_yearly_aggregated = spark.sql(agg_query)

# Convert the aggregated Spark DataFrame to a Pandas DataFrame for plotting
pandas_aggregated = df_yearly_aggregated.toPandas()

# Plotting
plt.figure(figsize=(12, 6))

# Plot TotalViews
plt.plot(pandas_aggregated['Year'], pandas_aggregated['TotalViews'], label='Total Views', marker='o')

# Plot TotalHelpfulReviews
plt.plot(pandas_aggregated['Year'], pandas_aggregated['TotalHelpfulReviews'], label='Total Helpful Reviews', marker='x')

# Adding title and labels
plt.title('Total Views and Helpful Reviews by Year')
plt.xlabel('Year')
plt.ylabel('Count')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Show legend
plt.legend()

# Display the plot
plt.tight_layout()  # Adjusts plot to ensure everything fits without overlapping

plt.show()

# %matplot plt

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# Run SQL query to aggregate data by year for years after 1995
agg_query = """
SELECT YEAR(Time) as Year, SUM(NViews) as TotalViews, SUM(NHelpfulReview) as TotalHelpfulReviews
FROM reviews_rating
GROUP BY YEAR(Time)
ORDER BY YEAR(Time)
"""
df_yearly_aggregated = spark.sql(agg_query)

# Convert the aggregated Spark DataFrame to a Pandas DataFrame for plotting
pandas_aggregated = df_yearly_aggregated.toPandas()

# Plotting
plt.figure(figsize=(14, 7))

# Creating bar width
bar_width = 0.35

# Set position of bar on X axis
r1 = range(len(pandas_aggregated['Year']))
r2 = [x + bar_width for x in r1]

# Make the plot
plt.bar(r1, pandas_aggregated['TotalViews'], color='blue', width=bar_width, edgecolor='grey', label='Total Views')
plt.bar(r2, pandas_aggregated['TotalHelpfulReviews'], color='red', width=bar_width, edgecolor='grey', label='Total Helpful Reviews')

# Adding title and labels
plt.title('Total Views and Helpful Reviews by Year (From 1995 Onwards)')
plt.xlabel('Year', fontweight='bold')
plt.ylabel('Count', fontweight='bold')
plt.xticks([r + bar_width for r in range(len(pandas_aggregated['Year']))], pandas_aggregated['Year'])

# Create legend & Show graphic
plt.legend()
plt.show()
# %matplot plt

# 3
# New vs. Old Books Comparison
# Compare the average ratings of new books (e.g., published in the last 5 years) versus older books.

spark.sql("""
SELECT
    CASE
        WHEN YEAR(B.PublishedDate) >= YEAR(CURDATE()) - 5 THEN 'New Books'
        ELSE 'Old Books'
    END as BookType,
    AVG(RR.Score) as AvgScore
FROM Books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY BookType;
""").show()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# Assuming 'df_book_type_scores' is the Spark DataFrame containing the result of your SQL query
df_book_type_scores = spark.sql("""
SELECT CASE
         WHEN YEAR(B.PublishedDate) >= YEAR(CURDATE()) - 5 THEN 'New Books'
         ELSE 'Old Books'
       END as BookType,
       AVG(RR.Score) as AvgScore
FROM Books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY BookType
""")

# Convert the DataFrame to Pandas for visualization
pandas_book_type_scores = df_book_type_scores.toPandas()

# Plotting
plt.figure(figsize=(8, 6))

# Create a bar chart
plt.bar(pandas_book_type_scores['BookType'], pandas_book_type_scores['AvgScore'], color=['blue', 'orange'])

# Add labels and title
plt.xlabel('Book Type')
plt.ylabel('Average Score')
plt.title('Comparison of Average Ratings: New Books vs. Old Books')

# Show the plot
plt.show()

# %matplot plt

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np

# Assuming 'df_book_type_scores' is the Spark DataFrame containing the result of your SQL query
df_book_type_scores = spark.sql("""
SELECT CASE
         WHEN YEAR(B.PublishedDate) >= YEAR(CURDATE()) - 5 THEN 'New Books'
         ELSE 'Old Books'
       END as BookType,
       AVG(RR.Score) as AvgScore
FROM Books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY BookType
""")

# Convert the DataFrame to Pandas for visualization
pandas_book_type_scores = df_book_type_scores.toPandas()

# Sort the DataFrame for consistent plotting
pandas_book_type_scores.sort_values('BookType', inplace=True)

# Get the x locations for the groups
ind = np.arange(len(pandas_book_type_scores))

# Plotting
plt.figure(figsize=(8, 6))

# Plot the average score for each book type as a dot on the plot
plt.plot(ind, pandas_book_type_scores['AvgScore'], 'o', markersize=10)

# Add a line to connect the dots
plt.plot(ind, pandas_book_type_scores['AvgScore'], '-', color='gray')

# Set the x-axis to show the book types
plt.xticks(ind, pandas_book_type_scores['BookType'])

# Add labels and title
plt.xlabel('Book Type')
plt.ylabel('Average Score')
plt.title('Comparison of Average Ratings: New Books vs. Old Books')

# Add grid
plt.grid(True)

# Show the plot
plt.show()



# %matplot plt

# 4
# Top 10 Categories with the Highest Average NHelpfulReview

spark.sql("""
SELECT B.categories, AVG(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.categories
ORDER BY NHelpfulReview DESC
LIMIT 10
""").show()

# 5
# Top 10 Categories with the Highest Sum NHelpfulReview

spark.sql("""
SELECT B.categories, SUM(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.categories
ORDER BY NHelpfulReview DESC
LIMIT 10
""").show()

# 6
# Sum NHelpfulReview by Author

spark.sql("""
SELECT authors, SUM(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.authors
ORDER BY NHelpfulReview DESC
LIMIT 10
""").show()

# 7
# Sum Score by Author

spark.sql("""
SELECT authors, SUM(RR.Score) as Score
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.authors
ORDER BY Score DESC
LIMIT 10
""").show()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# This code assumes that the DataFrame 'df_author_scores' contains the result of your SQL query
# Let's say you've run your SQL query and stored the result in 'df_author_scores'
df_author_scores = spark.sql("""
SELECT authors, SUM(RR.Score) as Score
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.authors
ORDER BY Score DESC
LIMIT 10
""")

# Convert the DataFrame to Pandas for visualization
pandas_author_scores = df_author_scores.toPandas()

# Sorting the DataFrame by 'Score' for better visualization
pandas_author_scores.sort_values('Score', inplace=True, ascending=True)

# Plotting
plt.figure(figsize=(10, 8))

# Create a horizontal bar chart
plt.barh(pandas_author_scores['authors'], pandas_author_scores['Score'], color='skyblue')

# Add labels and title
plt.xlabel('Total Score')
plt.ylabel('Authors')
plt.title('Top 10 Authors by Sum of Scores')

# Inverting the y-axis to have the highest score at the top
plt.gca().invert_yaxis()

# Optionally, add the data labels on the bars
for index, value in enumerate(pandas_author_scores['Score']):
    plt.text(value, index, str(value))

# Show the plot
plt.show()

# %matplot plt

# 8
# Average NHelpfulReview by Author

spark.sql("""
SELECT authors, AVG(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.authors
ORDER BY NHelpfulReview DESC
LIMIT 10
""").show()

# 9
# Top 10 Books(Title) with the Highest Average NHelpfulReview

spark.sql("""
SELECT B.Title, AVG(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Title
ORDER BY NHelpfulReview DESC
LIMIT 10
""").show()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# Assuming 'df_top_books' is the Spark DataFrame containing the result of your SQL query
df_top_books = spark.sql("""
SELECT B.Title, AVG(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Title
ORDER BY NHelpfulReview DESC
LIMIT 10
""")

# Convert the DataFrame to Pandas for visualization
pandas_top_books = df_top_books.toPandas()

# Sorting the DataFrame by 'NHelpfulReview' for better visualization
pandas_top_books.sort_values('NHelpfulReview', inplace=True, ascending=True)

# Plotting
plt.figure(figsize=(10, 8))

# Create a horizontal bar chart
plt.barh(pandas_top_books['Title'], pandas_top_books['NHelpfulReview'], color='skyblue')

# Add labels and title
plt.xlabel('Average Number of Helpful Reviews')
plt.ylabel('Book Title')
plt.title('Top 10 Books with the Highest Average Helpful Reviews')

# Show the plot
plt.show()
# %matplot plt

# 10
# Top 10 Books(Title) with the Highest Sum Score

spark.sql("""
SELECT B.Title, SUM(RR.Score) as Score
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Title
ORDER BY Score DESC
LIMIT 10
""").show()

# 11
# Top 10 Publisher with by RatingsCount

spark.sql("""
SELECT Publisher, SUM(RatingsCount) as RatingsCount
FROM books
GROUP BY Publisher
ORDER BY RatingsCount DESC
LIMIT 10
""").show()

# 12
# Top 10 Publisher with by NHelpfulReview

spark.sql("""
SELECT B.Publisher, SUM(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Publisher
ORDER BY NHelpfulReview DESC
LIMIT 10
""").show()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt

# Assuming 'df_top_publishers' is the Spark DataFrame containing the result of your SQL query
df_top_publishers = spark.sql("""
SELECT B.Publisher, SUM(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Publisher
ORDER BY NHelpfulReview DESC
LIMIT 10
""")

# Convert the DataFrame to Pandas for visualization
pandas_top_publishers = df_top_publishers.toPandas()

# Sorting the DataFrame by 'NHelpfulReview' for better visualization
pandas_top_publishers.sort_values('NHelpfulReview', inplace=True, ascending=True)

# Plotting
plt.figure(figsize=(10, 8))

# Create a horizontal bar chart
plt.barh(pandas_top_publishers['Publisher'], pandas_top_publishers['NHelpfulReview'], color='purple')

# Add labels and title
plt.xlabel('Sum of Helpful Reviews')
plt.ylabel('Publisher')
plt.title('Top 10 Publishers by Sum of Helpful Reviews')

# Show the plot
plt.show()
# %matplot plt

# 13
# Top 10 Publisher with by Average NHelpfulReview

spark.sql("""
SELECT B.Publisher, AVG(RR.NHelpfulReview) as NHelpfulReview
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Publisher
ORDER BY NHelpfulReview DESC
LIMIT 10
""").show()

# 14
# Top 10 Publisher with by Score

spark.sql("""
SELECT B.Publisher, SUM(RR.Score) as Score
FROM books B
JOIN reviews_rating RR ON B.Title = RR.Title
GROUP BY B.Publisher
ORDER BY Score DESC
LIMIT 10
""").show()



